{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T07:40:15.618474Z",
     "start_time": "2019-06-26T07:40:13.078027Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using plaidml.keras.backend backend.\n",
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_555x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 21,140,042\n",
      "Trainable params: 6,425,354\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os  # a conflict in my mac system\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "# from classification_models.resnet import ResNet18, preprocess_input\n",
    "\n",
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=\n",
    "    False,  #we are going to remove the top layer, VGG was trained for 1000 classes, here we only have two\n",
    "    input_shape=(224, 224, 3))\n",
    "\n",
    "# img size 224*224\n",
    "# https://keras.io/applications/#mobilenetv2\n",
    "# mobile_base = NASNetMobile(input_shape=(224,224,3), include_top=False, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
    "# mobile_base = ResNet18((224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "# this \"freezes\"\n",
    "conv_base.trainable = False\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fine Tuning\n",
    "# # we freeze all layers before block5_conv1\n",
    "# conv_base.trainable = True\n",
    "# set_trainable = False\n",
    "# for layer in conv_base.layers:\n",
    "#     if layer.name == 'block5_conv1':\n",
    "#         set_trainable = True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "#\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T06:35:29.323384Z",
     "start_time": "2019-06-26T06:35:28.522123Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate val set\n",
    "import os, shutil\n",
    "\n",
    "train_dir = \"/Users/ranxin/Downloads/state-farm-distracted-driver-detection/imgs/train\"\n",
    "val_dir = \"/Users/ranxin/Downloads/state-farm-distracted-driver-detection/imgs/val\"\n",
    "\n",
    "train_c0_dir=os.path.join(train_dir, 'c0')\n",
    "train_c1_dir=os.path.join(train_dir, 'c1')\n",
    "train_c2_dir=os.path.join(train_dir, 'c2')\n",
    "train_c3_dir=os.path.join(train_dir, 'c3')\n",
    "train_c4_dir=os.path.join(train_dir, 'c4')\n",
    "train_c5_dir=os.path.join(train_dir, 'c5')\n",
    "train_c6_dir=os.path.join(train_dir, 'c6')\n",
    "train_c7_dir=os.path.join(train_dir, 'c7')\n",
    "train_c8_dir=os.path.join(train_dir, 'c8')\n",
    "train_c9_dir=os.path.join(train_dir, 'c9')\n",
    "\n",
    "val_c0_dir=os.path.join(val_dir, 'c0')\n",
    "val_c1_dir=os.path.join(val_dir, 'c1')\n",
    "val_c2_dir=os.path.join(val_dir, 'c2')\n",
    "val_c3_dir=os.path.join(val_dir, 'c3')\n",
    "val_c4_dir=os.path.join(val_dir, 'c4')\n",
    "val_c5_dir=os.path.join(val_dir, 'c5')\n",
    "val_c6_dir=os.path.join(val_dir, 'c6')\n",
    "val_c7_dir=os.path.join(val_dir, 'c7')\n",
    "val_c8_dir=os.path.join(val_dir, 'c8')\n",
    "val_c9_dir=os.path.join(val_dir, 'c9')\n",
    "\n",
    "n=0\n",
    "files= os.listdir(train_c0_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c0_dir, i)\n",
    "        dst = os.path.join(val_c0_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c1_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c1_dir, i)\n",
    "        dst = os.path.join(val_c1_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c2_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c2_dir, i)\n",
    "        dst = os.path.join(val_c2_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c3_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c3_dir, i)\n",
    "        dst = os.path.join(val_c3_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c4_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c4_dir, i)\n",
    "        dst = os.path.join(val_c4_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c5_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c5_dir, i)\n",
    "        dst = os.path.join(val_c5_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c6_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c6_dir, i)\n",
    "        dst = os.path.join(val_c6_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c7_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c7_dir, i)\n",
    "        dst = os.path.join(val_c7_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c8_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c8_dir, i)\n",
    "        dst = os.path.join(val_c8_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "n=0\n",
    "files= os.listdir(train_c9_dir)\n",
    "for i in files:\n",
    "    if not os.path.isdir(i):\n",
    "        src = os.path.join(train_c9_dir, i)\n",
    "        dst = os.path.join(val_c9_dir, i)\n",
    "        shutil.move(src, dst)\n",
    "        n=n+1\n",
    "        if n>400:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T07:40:23.391368Z",
     "start_time": "2019-06-26T07:40:22.823780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18414 images belonging to 10 classes.\n",
      "Found 4010 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = \"/Users/ranxin/Downloads/state-farm-distracted-driver-detection/imgs/train\"\n",
    "test_dir = \"/Users/ranxin/Downloads/state-farm-distracted-driver-detection/imgs/val\"\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "test_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=40, class_mode='categorical')\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=40,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T07:40:25.230034Z",
     "start_time": "2019-06-26T07:40:24.662979Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "    metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-26T07:46:00.855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 71 of 251 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/400 [======>.......................] - ETA: 10:41 - loss: 0.9669 - acc: 0.6951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 62 of 251 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 120 of 251 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/400 [============================>.] - ETA: 2s - loss: 0.9712 - acc: 0.6930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 73 of 179 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1027s 3s/step - loss: 0.9712 - acc: 0.6931 - val_loss: 0.4416 - val_acc: 0.8747\n",
      "Epoch 2/2\n",
      "399/400 [============================>.] - ETA: 2s - loss: 0.9503 - acc: 0.7005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 61 of 179 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 112 of 179 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "400/400 [==============================] - 1020s 3s/step - loss: 0.9508 - acc: 0.7002 - val_loss: 0.4441 - val_acc: 0.8691\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('Distracted_vgg16.h5', by_name=True)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=400,\n",
    "    epochs=2,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=80)\n",
    "\n",
    "model.save_weights('Distracted_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T07:45:04.246127Z",
     "start_time": "2019-06-26T07:45:03.037057Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('Distracted_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
